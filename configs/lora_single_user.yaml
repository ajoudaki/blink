# LoRA single-user configuration for fast testing
# Uses smallest CLIP model and single user's data

# CLIP model to use - ViT-B/32 is the basic Vision Transformer
clip_model: "ViT-B/32"  # Basic ViT model

# LoRA specific parameters
lora:
  rank: 4  # LoRA rank
  alpha: 1.0  # LoRA scaling factor
  temperature: 0.07  # Temperature for similarity softmax

# Training parameters
training:
  max_epochs: 5  # Quick test
  batch_size: 128  # Large batch for speed
  learning_rate: 0.0005  # Higher LR for faster convergence
  weight_decay: 0.01  # Weight decay
  patience: 3  # Early stopping patience
  min_delta: 0.001  # Minimum improvement
  eval_batch_size: 256  # Large eval batch for speed

# Data parameters
data:
  val_split: 0.15  # Validation split
  test_split: 0.15  # Test split
  num_workers: 2  # Data loading workers
  single_user: "5fc68c7d781dffc92b8a11e5"  # Top user with 4602 labels

# GPU settings
gpu:
  device_id: 1

# Random seed
seed: 42