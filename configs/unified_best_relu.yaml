task_type: comparison

model:
  hidden_dims: [384, 256, 128, 64, 32]  # Best 5-layer deep narrow architecture
  activation: relu  # BEST: ReLU outperforms all others
  dropout: 0.15  # Best dropout
  batch_norm: false
  layer_norm: false
  use_user_encoding: false
  use_batchnorm: true  # Best normalization
  use_layernorm: false
  use_user_embedding: true
  user_embedding_dim: 32
  use_glu: false  # Standard linear layers

data:
  targets: ["attractive", "smart", "trustworthy"]
  embeddings_cache_file: "clip_embeddings_cache.pkl"
  force_recompute_embeddings: false

training:
  max_epochs: 200  # High number to let early stopping work
  epochs: 200  # For compatibility
  learning_rate: 0.001  # Best LR
  validation_split: 0.1  # 10% for validation
  test_split: 0.1  # 10% for test
  augment_swapped_pairs: true
  optimizer: adamw
  weight_decay: 0.001  # Best weight decay
  batch_size: 128
  patience: 10  # Stop if no improvement for 10 epochs
  min_delta: 0.001  # Minimum change to consider as improvement

gpu:
  device_id: 1

seed: 42