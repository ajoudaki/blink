# Optimal configuration for ViT-L/14 with 768D embeddings
# Based on unified_optimal_final but adapted for larger embedding dimension

task_type: comparison

model:
  # Adjusted for 768D CLIP embeddings
  # Scale up first layer proportionally: 384 * (768/512) = 576
  hidden_dims: [576, 384, 256, 128, 64, 32]  # Scaled first layer for 768D
  activation: relu  # ReLU outperforms all others
  dropout: 0.1  # Optimized: lower dropout with higher LR
  batch_norm: false
  layer_norm: false
  use_user_encoding: false
  use_batchnorm: true  # Essential for performance
  use_layernorm: false
  use_user_embedding: true
  user_embedding_dim: 32
  use_glu: false  # Standard linear layers

data:
  targets: ["attractive", "smart", "trustworthy"]
  embeddings_cache_file: "clip_embeddings_cache.pkl"
  force_recompute_embeddings: false

training:
  max_epochs: 200  # High number to let early stopping work
  epochs: 200  # For compatibility
  learning_rate: 0.003  # Optimized: 3x higher than original
  validation_split: 0.1  # 10% for validation
  test_split: 0.1  # 10% for test
  augment_swapped_pairs: true
  optimizer: adamw
  weight_decay: 0.0  # Optimized: no weight decay
  batch_size: 128
  patience: 10  # Stop if no improvement for 10 epochs
  min_delta: 0.001  # Minimum change to consider as improvement

gpu:
  device_id: 1

seed: 42

# Performance expectations:
# Similar to 512D version but potentially better due to richer embeddings